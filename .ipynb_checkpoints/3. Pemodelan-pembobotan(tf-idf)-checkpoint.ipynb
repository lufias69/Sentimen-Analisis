{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import string, unicodedata\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fungsi fungsi ini digunakan untuk implementasi\n",
    "def replace_sw(teks):\n",
    "    teks_tokenize = teks.split()\n",
    "    for j in range(len(teks_tokenize)):\n",
    "        for k in range(len(diganti)):\n",
    "            if teks_tokenize[j]==diganti[k]:\n",
    "                teks_tokenize[j] = ganti[k]\n",
    "        for k in range(len(hapus)):\n",
    "            if teks_tokenize[j] == hapus[k]:\n",
    "                teks_tokenize[j]= ''\n",
    "    join = ' '.join(map(str,(teks_tokenize)))\n",
    "    join = re.sub('[\\s]+', ' ', join)\n",
    "    return join\n",
    "\n",
    "def removePunc(str):\n",
    "    str = re.sub(r'[^\\w]|_',' ',str)\n",
    "    str = re.sub(r\"\\b\\d+\\b\", \" \", str)\n",
    "    str = re.sub('[\\s]+', ' ', str)\n",
    "    return str\n",
    "#x = removePunc(replace_sw(teks))\n",
    "\n",
    "\n",
    "fo = pd.read_excel('data/karakter.xlsx', sheet_name='Sheet1')\n",
    "x = fo['karakter'].tolist() #\n",
    "y = fo['replace'].tolist()\n",
    "def gantiKarakter(str, x=x, y=y):\n",
    "    for i in range(len(x)):\n",
    "        if i == 0:\n",
    "            n_word = str\n",
    "        n_word = n_word.replace(x[i],y[i])\n",
    "    return unidecode(n_word).lower()\n",
    "\n",
    "def normalAt(str):\n",
    "    ok = gantiKarakter(str)\n",
    "    n_w = []\n",
    "    for i in range(len(ok)):\n",
    "        if ok[i] == \"@\" and i !=0 and ok[i-1] !=\" \":\n",
    "            n_w.append(\" @\")\n",
    "        else:\n",
    "            n_w.append(ok[i])\n",
    "    return \"\".join(n_w)\n",
    "\n",
    "def cleaning(str):\n",
    "    #remove non-ascii\n",
    "    str = unicodedata.normalize('NFKD', str).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    #remove URLs\n",
    "    str = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', str)\n",
    "    str = str.lower()\n",
    "    #Remove additional white spaces\n",
    "    str = re.sub('[\\s]+', ' ', str)\n",
    "       \n",
    "    return str\n",
    "def getJtext(text):\n",
    "    words = re.findall(r'[a-z0-9@.]+', text)\n",
    "    return ' '.join(words)\n",
    "def preprocessing1(str):\n",
    "    text = cleaning(normalAt(str))\n",
    "    text = getJtext(text)\n",
    "    return text\n",
    "\n",
    "def justCek(alpha, gamma, C):\n",
    "    for i in C:\n",
    "        if len(C)== len(gamma) and len(gamma)==len(alpha):\n",
    "            continue\n",
    "        else:\n",
    "            print(\"banyaknya data gamma c dan aplha harus sama\")\n",
    "        if i <= 0:\n",
    "            print (\"Nilai C harus lebih besar dari 0\")\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "factoryStop = StopWordRemoverFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stopword = factoryStop.create_stop_word_remover()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/data_komentar_clean_1.xlsx', sheet_name = 'Sheet1')\n",
    "komentar = data['komentar'].tolist()\n",
    "label = data['label'].tolist()\n",
    "kode = data['kode'].tolist()\n",
    "\n",
    "\n",
    "data_replace  = pd.read_excel('data/Corpus_kata_replace_new.xlsx', sheet_name = 'kata_repalce')\n",
    "data_hapus  = pd.read_excel('data/Corpus_kata_replace_new.xlsx', sheet_name = 'kata_hapus')\n",
    "diganti = data_replace['kata'].tolist()\n",
    "ganti = data_replace['ganti'].tolist()\n",
    "hapus = data_hapus['kata'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proses membuat vocabularry\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#kosa_kata = set()\n",
    "\n",
    "#seleksi fitur\n",
    "#kk = TfidfVectorizer()\n",
    "#kk.fit_transform(komentar)\n",
    "#kosa_kata = kk.get_feature_names()\n",
    "#print(len(kosa_kata))\n",
    "#with open('model/feature.txt', 'w') as f:\n",
    "    #for item in kosa_kata:\n",
    "        #f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 13065)\n"
     ]
    }
   ],
   "source": [
    "#membuat TF-IDF\n",
    "f = open(\"model/feature.txt\")\n",
    "kosa_kata = f.read().split()\n",
    "\n",
    "tfidf = TfidfVectorizer(vocabulary = kosa_kata)\n",
    "##Membuat Matrix TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(komentar)\n",
    "print(tfidf_matrix.shape)\n",
    "X = tfidf_matrix.toarray()\n",
    "Y = np.array(label)\n",
    "y=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Pemodelan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "#from sklearn.naive_bayes import Gaus\n",
    "#sianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menentukan C, gamma dan alpha untuk percobaan\n",
    "#C     = [1, 10]      #Harus titik, bukan koma\n",
    "#gamma = [1, 0.00001]\n",
    "#alpha = [1, 1]\n",
    "#akurasi_svm = []\n",
    "\n",
    "#justCek(C=C, gamma=gamma, alpha = alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jangan dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Uji 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = 1   #maksimal 4\n",
    "print(\"Data Uji \"+str(data))\n",
    "for i in range(len(C)):\n",
    "    cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "    comNB = ComplementNB(alpha = alpha[1])\n",
    "    \n",
    "    # latih classifier\n",
    "    x_latih =\"x_latih\"+str(data)\n",
    "    y_latih = \"y_latih\"+str(data)\n",
    "    cSVM = cSVM.fit(vars()[x_latih], vars()[y_latih])\n",
    "    comNB = comNB.fit(vars()[x_latih], vars()[y_latih])\n",
    "    \n",
    "    x_uji = \"x_uji\"+str(data)\n",
    "    #prediksi\n",
    "    P_SVM = cSVM.predict(vars()[x_uji])\n",
    "    P_CNB = comNB.predict(vars()[x_uji])\n",
    "    \n",
    "    y_uji = \"y_uji\"+str(data)\n",
    "    print(\"gamma : \", gamma[i])\n",
    "    print(\"C     : \", C[i])\n",
    "    print(\"Akurasi SVM          : %.2f\" % round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "    print(\"Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(vars()[y_uji], P_CNB),2))\n",
    "    print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    akurasi_svm.append(round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "    #Lumayan lama, Mohon bersabar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jangan Dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Uji 1\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.54\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 2\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.51\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 3\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.56\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 4\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.90\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.55\n",
      "   Akurasi C Naive Bayes: 0.90\n",
      "   ++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "#menjalankan seluruh data uji\n",
    "#prosesnya sangat lama, saran,  jangan di-run kalau belum siap\n",
    "\n",
    "for d in range(1,5):\n",
    "    data = d\n",
    "    print(\"Data Uji \"+str(data))\n",
    "    for i in range(len(C)):\n",
    "        cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "        comNB = ComplementNB(alpha = alpha[1])\n",
    "    \n",
    "        # latih classifier\n",
    "        x_latih =\"x_latih\"+str(data)\n",
    "        y_latih = \"y_latih\"+str(data)\n",
    "        cSVM = cSVM.fit(vars()[x_latih], vars()[y_latih])\n",
    "        comNB = comNB.fit(vars()[x_latih], vars()[y_latih])\n",
    "    \n",
    "        x_uji = \"x_uji\"+str(data)\n",
    "        #prediksi\n",
    "        P_SVM = cSVM.predict(vars()[x_uji])\n",
    "        P_CNB = comNB.predict(vars()[x_uji])\n",
    "    \n",
    "        y_uji = \"y_uji\"+str(data)\n",
    "        print(\"   gamma : \", gamma[i])\n",
    "        print(\"       C : \", C[i])\n",
    "        print(\"   Akurasi SVM          : %.2f\" % round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "        print(\"   Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(vars()[y_uji], P_CNB),2))\n",
    "        print('   ++++++++++++++++++++++++++++')\n",
    "#Lumayan sangat lama, Mohon bersabar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cek Akurasi 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji Validasi Cross Validations\n",
    "\n",
    "#### jangan dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c0b591edddff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(\"Data Uji \"+str(data))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#Jika ada SVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#for i in range(len(alpha)-1): #jika hanya SNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv = 4\n",
    "for d in range(1,5):\n",
    "    data = d\n",
    "    #print(\"Data Uji \"+str(data))\n",
    "    for i in range(len(alpha)): #Jika ada SVM\n",
    "    #for i in range(len(alpha)-1): #jika hanya SNB\n",
    "        cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "        comNB = ComplementNB(alpha = alpha[i])\n",
    "\n",
    "        print(\"SVM data uji \"+str(data))\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        scores = cross_val_score(cSVM, X, Y, cv=cv)\n",
    "        print(\"   gamma : \", gamma[i])\n",
    "        print(\"       C : \", C[i])\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %0.2f\" % (scores.mean()))\n",
    "        toc = time.perf_counter()\n",
    "        print(\"________________________________________________________Waktu Eksekusi : \",toc - tic, \"Detik\")\n",
    "        print(\" CNB data uji \"+str(data))\n",
    "        tic = time.perf_counter()\n",
    "        scores = cross_val_score(comNB, X, Y, cv=cv)\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %0.2f\" % (scores.mean()))\n",
    "        toc = time.perf_counter()\n",
    "        print(\"_________________________________________________________Waktu Eksekusi : \",toc - tic, \"Detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Menentukan Gamma, C dan alpha berapa yang akan di gunakan\n",
    "#mSVM = svm.SVC(kernel='rbf', gamma=0.00001, C=10)\n",
    "#mCNB = ComplementNB(alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation \n",
    "### jalanin aja dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi ke- 0\n",
      "   Akurasi SVM          : 0.92\n",
      "   Akurasi C Naive Bayes: 0.94\n",
      "iterasi ke- 1\n",
      "   Akurasi SVM          : 0.92\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "iterasi ke- 2\n",
      "   Akurasi SVM          : 0.92\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "iterasi ke- 3\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.91\n",
      "---------------------------------\n",
      "C     :  1.8\n",
      "gamma :  0.6\n",
      "alpha :  0.18\n",
      "----------------------------\n",
      "Rata-rata Akurasi SVM: 0.92\n",
      "Rata-rata Akurasi CNB: 0.92\n"
     ]
    }
   ],
   "source": [
    "K = 4 # K-> jumlah pembagian data latih dan data uji\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold #import librari\n",
    "kf = KFold(n_splits=K) \n",
    "akurasi_svm = []\n",
    "akurasi_cnb = []\n",
    "count=0\n",
    "\n",
    "C = 1.8\n",
    "gamma = 0.6\n",
    "alpha = 0.18\n",
    "cSVM = svm.SVC(kernel='rbf', gamma=gamma, C=C) #model\n",
    "comNB = ComplementNB(alpha = alpha)            #model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #membagi data latih dan data uji\n",
    "    X_train, X_test = X[train_index], X[test_index] #pembagian data latih\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Melatih Model \n",
    "    cSVM = cSVM.fit(X_train, y_train) #SVN\n",
    "    comNB = comNB.fit(X_train, y_train) #CNB\n",
    "    \n",
    "    P_SVM = cSVM.predict(X_test)\n",
    "    P_CNB = comNB.predict(X_test)\n",
    "    \n",
    "    print(\"iterasi ke-\", count)\n",
    "    print(\"   Akurasi SVM          : %.2f\" % round(accuracy_score(y_test, P_SVM),2))\n",
    "    akurasi_svm.append(accuracy_score(y_test, P_SVM))\n",
    "    print(\"   Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(y_test, P_CNB),2))\n",
    "    akurasi_cnb.append(accuracy_score(y_test, P_CNB))\n",
    "    count+=1\n",
    "#Menamplkan hasil akhri\n",
    "print(\"---------------------------------\")\n",
    "print(\"C     : \", C)\n",
    "print(\"gamma : \", gamma)\n",
    "print(\"alpha : \", alpha)\n",
    "print(\"----------------------------\")\n",
    "print(\"Rata-rata Akurasi SVM: %0.4f\" % (sum(akurasi_svm)/len(akurasi_svm)))\n",
    "print(\"Rata-rata Akurasi CNB: %0.4f\" % (sum(akurasi_cnb)/len(akurasi_cnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rata-rata Akurasi SVM: 0.9197\n",
      "Rata-rata Akurasi CNB: 0.9245\n"
     ]
    }
   ],
   "source": [
    "print(\"Rata-rata Akurasi SVM: %0.4f\" % (sum(akurasi_svm)/len(akurasi_svm)))\n",
    "print(\"Rata-rata Akurasi CNB: %0.4f\" % (sum(akurasi_cnb)/len(akurasi_cnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9105263157894737, 0.9084210526315789, 0.911578947368421, 0.9052631578947369]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akurasi_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSVM = svm.SVC(kernel='rbf', gamma=1, C=1)\n",
    "comNB = ComplementNB(alpha = 1)\n",
    "#Melatih Model untuk data secara keseluruhan (X dan Y)\n",
    "cSVM = cSVM.fit(X, Y) #SVN\n",
    "comNB = comNB.fit(X, Y) #CNB\n",
    "\n",
    "#save models\n",
    "filename = 'model\\cSVM.sav'\n",
    "pickle.dump(cSVM, open(filename, 'wb'))\n",
    "filename = 'model\\comNB.sav'\n",
    "pickle.dump(comNB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  komentar baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komentar: lelah\n",
      "==============================================================================================================================\n",
      "lelah\n",
      "==============================================================================================================================\n",
      "Prediksi SVM (TF-IDF)           :  ['bukan spam']\n",
      "Prediksi C Naive Bayes (TF-IDF) :  ['bukan spam']\n",
      "(3800, 13065)\n"
     ]
    }
   ],
   "source": [
    "t_komentar = komentar\n",
    "\n",
    "#input_komentar = \"Cek IG kami Kak, solusiii naiiikkk tinggiiii sampe 175cm, bahkan sampe umuur 33th masih bisa looh, Buruaaaaannn. '\"\n",
    "input_komentar = input(\"Komentar: \")\n",
    "#komentar  = [cleaning2(input_komentar)]\n",
    "komentar0 = preprocessing1(input_komentar)\n",
    "\n",
    "komentar_ = stemmer.stem(str(komentar0))\n",
    "komentar_ = stopword.remove(komentar_)\n",
    "t_komentar[-1]=komentar_\n",
    "print(\"==============================================================================================================================\")\n",
    "print(komentar0)\n",
    "print(\"==============================================================================================================================\")\n",
    "\n",
    "#t_clean_komentar_hapus = komentar_akhir\n",
    "#komentar_siap = []\n",
    "#komentar_siap.append(komentar)\n",
    "#vocabulary = koso_kata\n",
    "t_tfidf_matrix = tfidf.fit_transform(t_komentar)\n",
    "\n",
    "data_X = t_tfidf_matrix.toarray()\n",
    "#cek \n",
    "#x_cek = data_X[len(t_clean_komentar_hapus)-1:len(t_clean_komentar_hapus)]\n",
    "x_cek = data_X[len(t_komentar)-1:len(t_komentar)]\n",
    "#x_cek = data_X[-1]\n",
    "\n",
    "# prediksi data asli\n",
    "P_SVM = cSVM.predict(x_cek)\n",
    "P_NB = comNB.predict(x_cek)\n",
    "\n",
    "# print prediksi\n",
    "print(\"Prediksi SVM (TF-IDF)           : \", P_SVM)\n",
    "print(\"Prediksi C Naive Bayes (TF-IDF) : \", P_NB)\n",
    "print(t_tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediksi komentar baru lebih dari satu komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_implentasi(komentar):\n",
    "    n_komentar = []\n",
    "    for teks in komentar:\n",
    "        proses = preprocessing1(teks)\n",
    "        #proses = removePunc(replace_sw(proses))\n",
    "        proses = removePunc(proses)\n",
    "        proses = stemmer.stem(str(proses))\n",
    "        proses = stopword.remove(proses)\n",
    "        n_komentar.append(proses)\n",
    "    return n_komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "input_ = pd.read_excel(\"coba prediksi.xlsx\") #memasukkan nama file excel berisi komentar baru (yang akan di cek)\n",
    "\n",
    "\n",
    "input_list = input_['komentar'].tolist()\n",
    "f_komentar = [\"\" for x in range (3800)]\n",
    "list_komentar = input_list\n",
    "#list_komentar = [\"saud adaid aji\", \"suka kaming\", \"gule china\"]\n",
    "#list_komentar = new_komentar\n",
    "join_komentar = preprocessing_implentasi(list_komentar) + f_komentar\n",
    "print(\"*\")\n",
    "kokom = join_komentar[:3800]\n",
    "f = open(\"model/feature.txt\") \n",
    "voc = f.read().split()\n",
    "t_tfidf = TfidfVectorizer(vocabulary = voc)\n",
    "t_tfidf_matrix = tfidf.fit_transform(kokom)\n",
    "cek_komentar = t_tfidf_matrix[:len(list_komentar)]\n",
    "cek_komentar = cek_komentar.toarray()\n",
    "\n",
    "#melakukan prediksi untuk komentar baru\n",
    "P_SVM = cSVM.predict(cek_komentar)\n",
    "P_NB = comNB.predict(cek_komentar)\n",
    "\n",
    "\n",
    "dict = {'komentar':input_list, \"prediksi svm\":P_SVM, \"prediksi CNB\": P_NB}\n",
    "df = pd.DataFrame(dict, columns=['komentar',\"prediksi svm\",\"prediksi CNB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>komentar</th>\n",
       "      <th>prediksi svm</th>\n",
       "      <th>prediksi CNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assalamualaikum wr.wb..!!!*PROMO BIG SALE 2018...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yg msh kangen momen2 asian games bisa klik lin...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok klau begitu saya coba pake panelpediavip.co...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ғollowwww IG @Marcella.beauty_specialist  gaaa...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moga lancar n sukses y kak via besuk sore diko...</td>\n",
       "      <td>bukan spam</td>\n",
       "      <td>bukan spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Semingguuu yang laluuuu akuuu cobaaa cekkk ins...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THÀNKSSSSSS ÝÀ KÀK ÚDÀHHHHHHHH KÀSÌHHHHHHHH TÀ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MÁŚĶĔŔ ŴÁĴÁĤŃŶÁ oĶĔ ßÁŃĞĔŤ ĶÁĶ ŚĔĶÁŔÁŃĞ ŴÁĴÁĤĶ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ÀJÀÌBBBBBBBBB ρRÓDÚKNÝÀÀÀÀÀÀ KÀK , BÀNÝÀKKKKK ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            komentar prediksi svm prediksi CNB\n",
       "0  Assalamualaikum wr.wb..!!!*PROMO BIG SALE 2018...         spam         spam\n",
       "1  yg msh kangen momen2 asian games bisa klik lin...         spam         spam\n",
       "2  ok klau begitu saya coba pake panelpediavip.co...         spam         spam\n",
       "3  Ғollowwww IG @Marcella.beauty_specialist  gaaa...         spam         spam\n",
       "4  Moga lancar n sukses y kak via besuk sore diko...   bukan spam   bukan spam\n",
       "5  Semingguuu yang laluuuu akuuu cobaaa cekkk ins...         spam         spam\n",
       "6  THÀNKSSSSSS ÝÀ KÀK ÚDÀHHHHHHHH KÀSÌHHHHHHHH TÀ...         spam         spam\n",
       "7  MÁŚĶĔŔ ŴÁĴÁĤŃŶÁ oĶĔ ßÁŃĞĔŤ ĶÁĶ ŚĔĶÁŔÁŃĞ ŴÁĴÁĤĶ...         spam         spam\n",
       "8  ÀJÀÌBBBBBBBBB ρRÓDÚKNÝÀÀÀÀÀÀ KÀK , BÀNÝÀKKKKK ...         spam         spam"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
