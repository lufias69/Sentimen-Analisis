{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import string, unicodedata\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fungsi fungsi ini digunakan untuk implementasi\n",
    "def replace_sw(teks):\n",
    "    teks_tokenize = teks.split()\n",
    "    for j in range(len(teks_tokenize)):\n",
    "        for k in range(len(diganti)):\n",
    "            if teks_tokenize[j]==diganti[k]:\n",
    "                teks_tokenize[j] = ganti[k]\n",
    "        for k in range(len(hapus)):\n",
    "            if teks_tokenize[j] == hapus[k]:\n",
    "                teks_tokenize[j]= ''\n",
    "    join = ' '.join(map(str,(teks_tokenize)))\n",
    "    join = re.sub('[\\s]+', ' ', join)\n",
    "    return join\n",
    "\n",
    "def removePunc(str):\n",
    "    str = re.sub(r'[^\\w]|_',' ',str)\n",
    "    str = re.sub(r\"\\b\\d+\\b\", \" \", str)\n",
    "    str = re.sub('[\\s]+', ' ', str)\n",
    "    return str\n",
    "#x = removePunc(replace_sw(teks))\n",
    "\n",
    "\n",
    "fo = pd.read_excel('data/karakter.xlsx', sheet_name='Sheet1')\n",
    "x = fo['karakter'].tolist() #\n",
    "y = fo['replace'].tolist()\n",
    "def gantiKarakter(str, x=x, y=y):\n",
    "    for i in range(len(x)):\n",
    "        if i == 0:\n",
    "            n_word = str\n",
    "        n_word = n_word.replace(x[i],y[i])\n",
    "    return unidecode(n_word).lower()\n",
    "\n",
    "def normalAt(str):\n",
    "    ok = gantiKarakter(str)\n",
    "    n_w = []\n",
    "    for i in range(len(ok)):\n",
    "        if ok[i] == \"@\" and i !=0 and ok[i-1] !=\" \":\n",
    "            n_w.append(\" @\")\n",
    "        else:\n",
    "            n_w.append(ok[i])\n",
    "    return \"\".join(n_w)\n",
    "\n",
    "def cleaning(str):\n",
    "    #remove non-ascii\n",
    "    str = unicodedata.normalize('NFKD', str).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    #remove URLs\n",
    "    str = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', str)\n",
    "    str = str.lower()\n",
    "    #Remove additional white spaces\n",
    "    str = re.sub('[\\s]+', ' ', str)\n",
    "       \n",
    "    return str\n",
    "def getJtext(text):\n",
    "    words = re.findall(r'[a-z0-9@.]+', text)\n",
    "    return ' '.join(words)\n",
    "def preprocessing1(str):\n",
    "    text = cleaning(normalAt(str))\n",
    "    text = getJtext(text)\n",
    "    return text\n",
    "\n",
    "def justCek(alpha, gamma, C):\n",
    "    for i in C:\n",
    "        if len(C)== len(gamma) and len(gamma)==len(alpha):\n",
    "            continue\n",
    "        else:\n",
    "            print(\"banyaknya data gamma c dan aplha harus sama\")\n",
    "        if i <= 0:\n",
    "            print (\"Nilai C harus lebih besar dari 0\")\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "factoryStop = StopWordRemoverFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stopword = factoryStop.create_stop_word_remover()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/data_komentar_clean_1.xlsx', sheet_name = 'Sheet1')\n",
    "komentar = data['komentar'].tolist()\n",
    "label = data['label'].tolist()\n",
    "kode = data['kode'].tolist()\n",
    "\n",
    "\n",
    "data_replace  = pd.read_excel('data/Corpus_kata_replace_new.xlsx', sheet_name = 'kata_repalce')\n",
    "data_hapus  = pd.read_excel('data/Corpus_kata_replace_new.xlsx', sheet_name = 'kata_hapus')\n",
    "diganti = data_replace['kata'].tolist()\n",
    "ganti = data_replace['ganti'].tolist()\n",
    "hapus = data_hapus['kata'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proses membuat vocabularry\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#kosa_kata = set()\n",
    "\n",
    "#seleksi fitur\n",
    "#kk = TfidfVectorizer()\n",
    "#kk.fit_transform(komentar)\n",
    "#kosa_kata = kk.get_feature_names()\n",
    "#print(len(kosa_kata))\n",
    "#with open('model/feature.txt', 'w') as f:\n",
    "    #for item in kosa_kata:\n",
    "        #f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 13065)\n"
     ]
    }
   ],
   "source": [
    "#membuat TF-IDF\n",
    "f = open(\"model/feature.txt\")\n",
    "kosa_kata = f.read().split()\n",
    "\n",
    "tfidf = TfidfVectorizer(vocabulary = kosa_kata)\n",
    "##Membuat Matrix TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(komentar)\n",
    "print(tfidf_matrix.shape)\n",
    "X = tfidf_matrix.toarray()\n",
    "Y = np.array(label)\n",
    "y=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Pembagian Data Latih dan Data Uji (Cara manual)\n",
    "Presentasi antara data latih dan data uji adalah 25:75, 25 persen sebagai data uji dan 75 persen sebagai data latih. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagi = 4\n",
    "sx = np.vsplit(X, bagi)\n",
    "sy = np.split(Y, bagi)\n",
    "\n",
    "#latih 1\n",
    "x_latih1 = np.concatenate((sx[1], sx[2], sx[3]))\n",
    "y_latih1 = np.concatenate((sy[1], sy[2], sy[3]))\n",
    "\n",
    "#uji 1\n",
    "x_uji1 = sx[0]\n",
    "y_uji1 = sy[0]\n",
    "\n",
    "#latih 2\n",
    "x_latih2 = np.concatenate((sx[0], sx[2], sx[3]))\n",
    "y_latih2 = np.concatenate((sy[0], sy[2], sy[3]))\n",
    "\n",
    "#uji 2\n",
    "x_uji2 = sx[1]\n",
    "y_uji2 = sy[1]\n",
    "\n",
    "#latih 3\n",
    "x_latih3 = np.concatenate((sx[0], sx[1], sx[3]))\n",
    "y_latih3 = np.concatenate((sy[0], sy[1], sy[3]))\n",
    "\n",
    "#uji 3\n",
    "x_uji3 = sx[2]\n",
    "y_uji3 = sy[2]\n",
    "\n",
    "#latih 4\n",
    "x_latih4 = np.concatenate((sx[0], sx[1], sx[2]))\n",
    "y_latih4 = np.concatenate((sy[0], sy[1], sy[2]))\n",
    "\n",
    "#uji 4\n",
    "x_uji4 = sx[3]\n",
    "y_uji4 = sy[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Pemodelan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menentukan C, gamma dan alpha untuk percobaan\n",
    "C     = [1, 10]      #Harus titik, bukan koma\n",
    "gamma = [1, 0.00001]\n",
    "alpha = [1, 1]\n",
    "akurasi_svm = []\n",
    "\n",
    "#justCek(C=C, gamma=gamma, alpha = alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jangan dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Uji 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = 1   #maksimal 4\n",
    "print(\"Data Uji \"+str(data))\n",
    "for i in range(len(C)):\n",
    "    cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "    comNB = ComplementNB(alpha = alpha[1])\n",
    "    \n",
    "    # latih classifier\n",
    "    x_latih =\"x_latih\"+str(data)\n",
    "    y_latih = \"y_latih\"+str(data)\n",
    "    cSVM = cSVM.fit(vars()[x_latih], vars()[y_latih])\n",
    "    comNB = comNB.fit(vars()[x_latih], vars()[y_latih])\n",
    "    \n",
    "    x_uji = \"x_uji\"+str(data)\n",
    "    #prediksi\n",
    "    P_SVM = cSVM.predict(vars()[x_uji])\n",
    "    P_CNB = comNB.predict(vars()[x_uji])\n",
    "    \n",
    "    y_uji = \"y_uji\"+str(data)\n",
    "    print(\"gamma : \", gamma[i])\n",
    "    print(\"C     : \", C[i])\n",
    "    print(\"Akurasi SVM          : %.2f\" % round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "    print(\"Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(vars()[y_uji], P_CNB),2))\n",
    "    print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    akurasi_svm.append(round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "    #Lumayan lama, Mohon bersabar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jangan Dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Uji 1\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.54\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 2\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.51\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 3\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.56\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "   ++++++++++++++++++++++++++++\n",
      "Data Uji 4\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.90\n",
      "   ++++++++++++++++++++++++++++\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "   Akurasi SVM          : 0.55\n",
      "   Akurasi C Naive Bayes: 0.90\n",
      "   ++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "#menjalankan seluruh data uji\n",
    "#prosesnya sangat lama, saran,  jangan di-run kalau belum siap\n",
    "\n",
    "for d in range(1,5):\n",
    "    data = d\n",
    "    print(\"Data Uji \"+str(data))\n",
    "    for i in range(len(C)):\n",
    "        cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "        comNB = ComplementNB(alpha = alpha[1])\n",
    "    \n",
    "        # latih classifier\n",
    "        x_latih =\"x_latih\"+str(data)\n",
    "        y_latih = \"y_latih\"+str(data)\n",
    "        cSVM = cSVM.fit(vars()[x_latih], vars()[y_latih])\n",
    "        comNB = comNB.fit(vars()[x_latih], vars()[y_latih])\n",
    "    \n",
    "        x_uji = \"x_uji\"+str(data)\n",
    "        #prediksi\n",
    "        P_SVM = cSVM.predict(vars()[x_uji])\n",
    "        P_CNB = comNB.predict(vars()[x_uji])\n",
    "    \n",
    "        y_uji = \"y_uji\"+str(data)\n",
    "        print(\"   gamma : \", gamma[i])\n",
    "        print(\"       C : \", C[i])\n",
    "        print(\"   Akurasi SVM          : %.2f\" % round(accuracy_score(vars()[y_uji], P_SVM),2))\n",
    "        print(\"   Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(vars()[y_uji], P_CNB),2))\n",
    "        print('   ++++++++++++++++++++++++++++')\n",
    "#Lumayan sangat lama, Mohon bersabar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cek Akurasi 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji Validasi Cross Validations\n",
    "\n",
    "#### jangan dijalankan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM data uji 1\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "[0.9106204  0.91587802 0.91043203 0.89989463]\n",
      "Accuracy: 0.91\n",
      "________________________________________________________Waktu Eksekusi :  1187.636867843 Detik\n",
      " CNB data uji 1\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.5080524900004093 Detik\n",
      "SVM data uji 1\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "[0.53943218 0.53943218 0.53951528 0.53951528]\n",
      "Accuracy: 0.54\n",
      "________________________________________________________Waktu Eksekusi :  1210.7622149179997 Detik\n",
      " CNB data uji 1\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.5350401790001342 Detik\n",
      "SVM data uji 2\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "[0.9106204  0.91587802 0.91043203 0.89989463]\n",
      "Accuracy: 0.91\n",
      "________________________________________________________Waktu Eksekusi :  1159.2712953150012 Detik\n",
      " CNB data uji 2\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.722211596001216 Detik\n",
      "SVM data uji 2\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "[0.53943218 0.53943218 0.53951528 0.53951528]\n",
      "Accuracy: 0.54\n",
      "________________________________________________________Waktu Eksekusi :  1146.4410518800014 Detik\n",
      " CNB data uji 2\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.4605768199999147 Detik\n",
      "SVM data uji 3\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "[0.9106204  0.91587802 0.91043203 0.89989463]\n",
      "Accuracy: 0.91\n",
      "________________________________________________________Waktu Eksekusi :  1060.6203402480005 Detik\n",
      " CNB data uji 3\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  4.202881911998702 Detik\n",
      "SVM data uji 3\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "[0.53943218 0.53943218 0.53951528 0.53951528]\n",
      "Accuracy: 0.54\n",
      "________________________________________________________Waktu Eksekusi :  1508.7959286799996 Detik\n",
      " CNB data uji 3\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  6.0037935929995 Detik\n",
      "SVM data uji 4\n",
      "   gamma :  1\n",
      "       C :  1\n",
      "[0.9106204  0.91587802 0.91043203 0.89989463]\n",
      "Accuracy: 0.91\n",
      "________________________________________________________Waktu Eksekusi :  1331.7024626080001 Detik\n",
      " CNB data uji 4\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.428503206998357 Detik\n",
      "SVM data uji 4\n",
      "   gamma :  1e-05\n",
      "       C :  10\n",
      "[0.53943218 0.53943218 0.53951528 0.53951528]\n",
      "Accuracy: 0.54\n",
      "________________________________________________________Waktu Eksekusi :  1327.2423183299998 Detik\n",
      " CNB data uji 4\n",
      "[0.93059937 0.92429022 0.92096944 0.90410959]\n",
      "Accuracy: 0.92\n",
      "_________________________________________________________Waktu Eksekusi :  3.6080960419985786 Detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv = 4\n",
    "for d in range(1,5):\n",
    "    data = d\n",
    "    #print(\"Data Uji \"+str(data))\n",
    "    for i in range(len(alpha)): #Jika ada SVM\n",
    "    #for i in range(len(alpha)-1): #jika hanya SNB\n",
    "        cSVM = svm.SVC(kernel='rbf', gamma=gamma[i], C=C[i])\n",
    "        comNB = ComplementNB(alpha = alpha[i])\n",
    "\n",
    "        print(\"SVM data uji \"+str(data))\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        scores = cross_val_score(cSVM, X, Y, cv=cv)\n",
    "        print(\"   gamma : \", gamma[i])\n",
    "        print(\"       C : \", C[i])\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %0.2f\" % (scores.mean()))\n",
    "        toc = time.perf_counter()\n",
    "        print(\"________________________________________________________Waktu Eksekusi : \",toc - tic, \"Detik\")\n",
    "        print(\" CNB data uji \"+str(data))\n",
    "        tic = time.perf_counter()\n",
    "        scores = cross_val_score(comNB, X, Y, cv=cv)\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %0.2f\" % (scores.mean()))\n",
    "        toc = time.perf_counter()\n",
    "        print(\"_________________________________________________________Waktu Eksekusi : \",toc - tic, \"Detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Menentukan Gamma, C dan alpha berapa yang akan di gunakan\n",
    "#mSVM = svm.SVC(kernel='rbf', gamma=0.00001, C=10)\n",
    "#mCNB = ComplementNB(alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation \n",
    "### jalanin aja dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi ke- 0\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "iterasi ke- 1\n",
      "   Akurasi SVM          : 0.92\n",
      "   Akurasi C Naive Bayes: 0.93\n",
      "iterasi ke- 2\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "iterasi ke- 3\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "iterasi ke- 4\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.91\n",
      "iterasi ke- 5\n",
      "   Akurasi SVM          : 0.91\n",
      "   Akurasi C Naive Bayes: 0.92\n",
      "---------------------------------\n",
      "C     :  1\n",
      "gamma :  1\n",
      "alpha :  1\n",
      "----------------------------\n",
      "Rata-rata Akurasi SVM: 0.91\n",
      "Rata-rata Akurasi CNB: 0.92\n"
     ]
    }
   ],
   "source": [
    "K = 6 # K-> jumlah pembagian data latih dan data uji\n",
    "kf = KFold(n_splits=K) \n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold #import librari\n",
    "akurasi_svm = []\n",
    "akurasi_cnb = []\n",
    "count=0\n",
    "\n",
    "C = 1\n",
    "gamma = 1\n",
    "alpha = 1\n",
    "cSVM = svm.SVC(kernel='rbf', gamma=gamma, C=C) #model\n",
    "comNB = ComplementNB(alpha = alpha)            #model\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #membagi data latih dan data uji\n",
    "    X_train, X_test = X[train_index], X[test_index] #pembagian data latih\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Melatih Model \n",
    "    cSVM = cSVM.fit(X_train, y_train) #SVN\n",
    "    comNB = comNB.fit(X_train, y_train) #CNB\n",
    "    \n",
    "    P_SVM = cSVM.predict(X_test)\n",
    "    P_CNB = comNB.predict(X_test)\n",
    "    \n",
    "    print(\"iterasi ke-\", count)\n",
    "    print(\"   Akurasi SVM          : %.2f\" % round(accuracy_score(y_test, P_SVM),2))\n",
    "    akurasi_svm.append(accuracy_score(y_test, P_SVM))\n",
    "    print(\"   Akurasi C Naive Bayes: %.2f\" % round(accuracy_score(y_test, P_CNB),2))\n",
    "    akurasi_cnb.append(accuracy_score(y_test, P_CNB))\n",
    "    count+=1\n",
    "#Menamplkan hasil akhri\n",
    "print(\"---------------------------------\")\n",
    "print(\"C     : \", C)\n",
    "print(\"gamma : \", gamma)\n",
    "print(\"alpha : \", alpha)\n",
    "print(\"----------------------------\")\n",
    "print(\"Rata-rata Akurasi SVM: %0.2f\" % (sum(akurasi_svm)/len(akurasi_svm)))\n",
    "print(\"Rata-rata Akurasi CNB: %0.2f\" % (sum(akurasi_cnb)/len(akurasi_cnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9105263157894737, 0.9084210526315789, 0.911578947368421, 0.9052631578947369]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akurasi_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tic = time.perf_counter()\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "#prediksi latih dan uji 1\n",
    "# latih classifier\n",
    "#cSVM_cr = cSVM.fit(x_latih1, y_latih1)\n",
    "#comNB_cr  = comNB.fit(x_latih1, y_latih1)\n",
    "\n",
    "#prediksi\n",
    "#Y_SVM = cSVM_cr.predict(x_uji1)\n",
    "#from sklearn.metrics import classification_report\n",
    "#y_true = y_uji1\n",
    "#y_pred = Y_SVM\n",
    "#print(\"SVM\")\n",
    "#target_names = [\"bukan spam\", \"spam\"]\n",
    "#print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "#toc = time.perf_counter()\n",
    "#print(\"Waktu Eksekusi : \",toc - tic, \"Detik\")\n",
    "\n",
    "#tic = time.perf_counter()\n",
    "#Y_NB = comNB_cr.predict(x_uji1)\n",
    "#y_true = y_uji1\n",
    "#y_pred = Y_NB\n",
    "#print(\"\")\n",
    "#print(\"CNB\")\n",
    "#target_names = [\"bukan spam\", \"spam\"]\n",
    "#print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "#toc = time.perf_counter()\n",
    "#print(\"Waktu Eksekusi : \",toc - tic, \"Detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSVM = svm.SVC(kernel='rbf', gamma=1, C=1)\n",
    "comNB = ComplementNB(alpha = 1)\n",
    "#Melatih Model untuk data secara keseluruhan (X dan Y)\n",
    "cSVM = cSVM.fit(X, Y) #SVN\n",
    "comNB = comNB.fit(X, Y) #CNB\n",
    "\n",
    "#save models\n",
    "filename = 'model\\cSVM.sav'\n",
    "pickle.dump(cSVM, open(filename, 'wb'))\n",
    "filename = 'model\\comNB.sav'\n",
    "pickle.dump(comNB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  komentar baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komentar: lelah\n",
      "==============================================================================================================================\n",
      "lelah\n",
      "==============================================================================================================================\n",
      "Prediksi SVM (TF-IDF)           :  ['bukan spam']\n",
      "Prediksi C Naive Bayes (TF-IDF) :  ['bukan spam']\n",
      "(3800, 13065)\n"
     ]
    }
   ],
   "source": [
    "t_komentar = komentar\n",
    "\n",
    "#input_komentar = \"Cek IG kami Kak, solusiii naiiikkk tinggiiii sampe 175cm, bahkan sampe umuur 33th masih bisa looh, Buruaaaaannn. '\"\n",
    "input_komentar = input(\"Komentar: \")\n",
    "#komentar  = [cleaning2(input_komentar)]\n",
    "komentar0 = preprocessing1(input_komentar)\n",
    "\n",
    "komentar_ = stemmer.stem(str(komentar0))\n",
    "komentar_ = stopword.remove(komentar_)\n",
    "t_komentar[-1]=komentar_\n",
    "print(\"==============================================================================================================================\")\n",
    "print(komentar0)\n",
    "print(\"==============================================================================================================================\")\n",
    "\n",
    "#t_clean_komentar_hapus = komentar_akhir\n",
    "#komentar_siap = []\n",
    "#komentar_siap.append(komentar)\n",
    "#vocabulary = koso_kata\n",
    "t_tfidf_matrix = tfidf.fit_transform(t_komentar)\n",
    "\n",
    "data_X = t_tfidf_matrix.toarray()\n",
    "#cek \n",
    "#x_cek = data_X[len(t_clean_komentar_hapus)-1:len(t_clean_komentar_hapus)]\n",
    "x_cek = data_X[len(t_komentar)-1:len(t_komentar)]\n",
    "#x_cek = data_X[-1]\n",
    "\n",
    "# prediksi data asli\n",
    "P_SVM = cSVM.predict(x_cek)\n",
    "P_NB = comNB.predict(x_cek)\n",
    "\n",
    "# print prediksi\n",
    "print(\"Prediksi SVM (TF-IDF)           : \", P_SVM)\n",
    "print(\"Prediksi C Naive Bayes (TF-IDF) : \", P_NB)\n",
    "print(t_tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediksi komentar baru lebih dari satu komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_implentasi(komentar):\n",
    "    n_komentar = []\n",
    "    for teks in komentar:\n",
    "        proses = preprocessing1(teks)\n",
    "        #proses = removePunc(replace_sw(proses))\n",
    "        proses = removePunc(proses)\n",
    "        proses = stemmer.stem(str(proses))\n",
    "        proses = stopword.remove(proses)\n",
    "        n_komentar.append(proses)\n",
    "    return n_komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n"
     ]
    }
   ],
   "source": [
    "input_ = pd.read_excel(\"coba prediksi.xlsx\") #memasukkan nama file excel berisi komentar baru (yang akan di cek)\n",
    "\n",
    "\n",
    "input_list = input_['komentar'].tolist()\n",
    "f_komentar = [\"\" for x in range (3800)]\n",
    "list_komentar = input_list\n",
    "#list_komentar = [\"saud adaid aji\", \"suka kaming\", \"gule china\"]\n",
    "#list_komentar = new_komentar\n",
    "join_komentar = preprocessing_implentasi(list_komentar) + f_komentar\n",
    "print(\"*\")\n",
    "kokom = join_komentar[:3800]\n",
    "f = open(\"model/feature.txt\") \n",
    "voc = f.read().split()\n",
    "t_tfidf = TfidfVectorizer(vocabulary = voc)\n",
    "t_tfidf_matrix = tfidf.fit_transform(kokom)\n",
    "cek_komentar = t_tfidf_matrix[:len(list_komentar)]\n",
    "cek_komentar = cek_komentar.toarray()\n",
    "\n",
    "#melakukan prediksi untuk komentar baru\n",
    "P_SVM = cSVM.predict(cek_komentar)\n",
    "P_NB = comNB.predict(cek_komentar)\n",
    "\n",
    "\n",
    "dict = {'komentar':input_list, \"prediksi svm\":P_SVM, \"prediksi CNB\": P_NB}\n",
    "df = pd.DataFrame(dict, columns=['komentar',\"prediksi svm\",\"prediksi CNB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>komentar</th>\n",
       "      <th>prediksi svm</th>\n",
       "      <th>prediksi CNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assalamualaikum wr.wb..!!!*PROMO BIG SALE 2018...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yg msh kangen momen2 asian games bisa klik lin...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok klau begitu saya coba pake panelpediavip.co...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ғollowwww IG @Marcella.beauty_specialist  gaaa...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moga lancar n sukses y kak via besuk sore diko...</td>\n",
       "      <td>bukan spam</td>\n",
       "      <td>bukan spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Semingguuu yang laluuuu akuuu cobaaa cekkk ins...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THÀNKSSSSSS ÝÀ KÀK ÚDÀHHHHHHHH KÀSÌHHHHHHHH TÀ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MÁŚĶĔŔ ŴÁĴÁĤŃŶÁ oĶĔ ßÁŃĞĔŤ ĶÁĶ ŚĔĶÁŔÁŃĞ ŴÁĴÁĤĶ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ÀJÀÌBBBBBBBBB ρRÓDÚKNÝÀÀÀÀÀÀ KÀK , BÀNÝÀKKKKK ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            komentar prediksi svm prediksi CNB\n",
       "0  Assalamualaikum wr.wb..!!!*PROMO BIG SALE 2018...         spam         spam\n",
       "1  yg msh kangen momen2 asian games bisa klik lin...         spam         spam\n",
       "2  ok klau begitu saya coba pake panelpediavip.co...         spam         spam\n",
       "3  Ғollowwww IG @Marcella.beauty_specialist  gaaa...         spam         spam\n",
       "4  Moga lancar n sukses y kak via besuk sore diko...   bukan spam   bukan spam\n",
       "5  Semingguuu yang laluuuu akuuu cobaaa cekkk ins...         spam         spam\n",
       "6  THÀNKSSSSSS ÝÀ KÀK ÚDÀHHHHHHHH KÀSÌHHHHHHHH TÀ...         spam         spam\n",
       "7  MÁŚĶĔŔ ŴÁĴÁĤŃŶÁ oĶĔ ßÁŃĞĔŤ ĶÁĶ ŚĔĶÁŔÁŃĞ ŴÁĴÁĤĶ...         spam         spam\n",
       "8  ÀJÀÌBBBBBBBBB ρRÓDÚKNÝÀÀÀÀÀÀ KÀK , BÀNÝÀKKKKK ...         spam         spam"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
